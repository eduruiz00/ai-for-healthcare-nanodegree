{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Pulse Rate Algorithm\n",
    "\n",
    "### Contents\n",
    "Fill out this notebook as part of your final project submission.\n",
    "\n",
    "**You will have to complete both the Code and Project Write-up sections.**\n",
    "- The [Code](#Code) is where you will write a **pulse rate algorithm** and already includes the starter code.\n",
    "   - Imports - These are the imports needed for Part 1 of the final project. \n",
    "     - [glob](https://docs.python.org/3/library/glob.html)\n",
    "     - [numpy](https://numpy.org/)\n",
    "     - [scipy](https://www.scipy.org/)\n",
    "- The [Project Write-up](#Project-Write-up) to describe why you wrote the algorithm for the specific case.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "You will be using the **Troika**[1] dataset to build your algorithm. Find the dataset under `datasets/troika/training_data`. The `README` in that folder will tell you how to interpret the data. The starter code contains a function to help load these files.\n",
    "\n",
    "1. Zhilin Zhang, Zhouyue Pi, Benyuan Liu, ‘‘TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise,’’IEEE Trans. on Biomedical Engineering, vol. 62, no. 2, pp. 522-531, February 2015. Link\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sampling frequency said\n",
    "fs = 125\n",
    "\n",
    "\n",
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "\n",
    "    Review the README in ./datasets/troika/ to understand the organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that ref_fls[5] is the \n",
    "            reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls\n",
    "\n",
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    return data[2:]\n",
    "\n",
    "def AggregateErrorMetric(pr_errors, confidence_est):\n",
    "    \"\"\"\n",
    "    Computes an aggregate error metric based on confidence estimates.\n",
    "\n",
    "    Computes the MAE at 90% availability. \n",
    "\n",
    "    Args:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates and corresponding \n",
    "            reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates for each pulse rate\n",
    "            error.\n",
    "\n",
    "    Returns:\n",
    "        the MAE at 90% availability\n",
    "    \"\"\"\n",
    "    # Higher confidence means a better estimate. The best 90% of the estimates\n",
    "    #    are above the 10th percentile confidence.\n",
    "    percentile90_confidence = np.percentile(confidence_est, 10)\n",
    "\n",
    "    # Find the errors of the best pulse rate estimates\n",
    "    best_estimates = pr_errors[confidence_est >= percentile90_confidence]\n",
    "\n",
    "    # Return the mean absolute error\n",
    "    return np.mean(np.abs(best_estimates))\n",
    "\n",
    "def Evaluate():\n",
    "    \"\"\"\n",
    "    Top-level function evaluation function.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns an aggregate error metric.\n",
    "\n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    # Retrieve dataset files\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    errs, confs = [], []\n",
    "    for data_fl, ref_fl in zip(data_fls, ref_fls):\n",
    "        # Run the pulse rate algorithm on each trial in the dataset\n",
    "        errors, confidence = RunPulseRateAlgorithm(data_fl, ref_fl)\n",
    "        errs.append(errors)\n",
    "        confs.append(confidence)\n",
    "        # Compute aggregate error metric\n",
    "    errs = np.hstack(errs)\n",
    "    confs = np.hstack(confs)\n",
    "    return AggregateErrorMetric(errs, confs)\n",
    "\n",
    "def RunPulseRateAlgorithm(data_fl, ref_fl):\n",
    "    '''Takes the data and the reference one and compares the values to measure the error and the confidence.\n",
    "    Both are returned.'''\n",
    "    # Load data using LoadTroikaDataFile\n",
    "    ppg, accx, accy, accz = LoadTroikaDataFile(data_fl)\n",
    "    bpm = sp.io.loadmat(ref_fl)['BPM0']\n",
    "    \n",
    "    # Compute pulse rate estimates and estimation confidence.\n",
    "    ppg = bandpass_filter(ppg)\n",
    "    accx = bandpass_filter(accx)\n",
    "    accy = bandpass_filter(accy)\n",
    "    accz = bandpass_filter(accz)\n",
    "    \n",
    "    # Take the frequency of the accelerometer by combining the three signals\n",
    "    acc = (accx**2 + accy**2 + accz**2)**(1/2)\n",
    "    \n",
    "    window_shift = 2*fs\n",
    "    window_length = 8*fs\n",
    "    \n",
    "    bpms = list()\n",
    "    confidence_list = list()\n",
    "    errors_list = list()\n",
    "    # We start with a previous of 100 which is a common value\n",
    "    previous = 100\n",
    "    for i in range(0, len(ppg)-window_length, window_shift):\n",
    "        part_ppg = ppg[i:i+window_length]\n",
    "        part_acc = acc[i:i+window_length]\n",
    "    \n",
    "        freq, freqs, fft = heart_rate_calc(ppg=part_ppg, acc=part_acc, fs=fs, prev = previous)\n",
    "        previous = freq\n",
    "        confidence_list.append(confidence_calc(freqs, fft, freq))\n",
    "        bpms.append(freq)\n",
    "    # Return per-estimate mean absolute error and confidence as a 2-tuple of numpy arrays.\n",
    "    confidence = np.array(confidence_list)\n",
    "    errors = np.array(np.abs(np.diag(np.subtract(bpms, bpm))))\n",
    "    return errors, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "def bandpass_filter(signal, band_pass = (70/60, 200/60), fs = fs):\n",
    "    \"\"\" Performs a bandpass filter on the signal. \"\"\"\n",
    "    \n",
    "    b,a = scipy.signal.butter(3, band_pass, fs=fs, btype= 'bandpass')\n",
    "    \n",
    "    # Perform forward and backward digital butterworth filter\n",
    "    return scipy.signal.filtfilt(b,a,signal)\n",
    "\n",
    "def fourier_transform(signal, fs):\n",
    "    '''Calculates the fourier transform for the signal (frequencies + fft)'''\n",
    "    freqs = np.fft.rfftfreq(len(signal), 1/fs)\n",
    "    fft = np.abs(np.fft.rfft(signal))\n",
    "    return freqs, fft\n",
    "\n",
    "def heart_rate_calc(ppg, acc, fs, prev):\n",
    "    \n",
    "    \"\"\"Takes the ppg, acc, fs and the previous frequency and calculates the heart rate depending on the\n",
    "    Fourier Transform and the previous frequency. It returns the frequency measured and the fft and frequencies of FFT.\"\"\"\n",
    "    \n",
    "    # Take the peaks of the fft\n",
    "    freq_ppg, fft_ppg = fourier_transform(ppg, fs)\n",
    "    \n",
    "    # Delete the fft at frequencies out of the range 70bpm to 200bpm\n",
    "    fft_ppg[freq_ppg <= 70/60.0] = 0.0\n",
    "    fft_ppg[freq_ppg >= 200/60.0] = 0.0\n",
    "    \n",
    "    # Calculate the peaks\n",
    "    peaks_ppg = sp.signal.find_peaks(fft_ppg)[0]\n",
    "    freq_peaks_ppg = freq_ppg[peaks_ppg]\n",
    "    \n",
    "    # Same with accelerometer signal\n",
    "    freq_acc, fft_acc = fourier_transform(acc, fs)\n",
    "    \n",
    "    # Delete the fft at frequencies out of the range 70bpm to 200bpm\n",
    "    fft_acc[freq_acc <= 70/60.0] = 0.0\n",
    "    fft_acc[freq_acc >= 200/60.0] = 0.0\n",
    "    \n",
    "    # Calculate the peaks\n",
    "    peaks_acc = sp.signal.find_peaks(fft_acc)[0]\n",
    "    freq_peaks_acc = freq_acc[peaks_acc]\n",
    "    \n",
    "    # The limit of frequency from the previous point is 11 bpm\n",
    "    limit = 11/60\n",
    "    delta = 2/60 #considered in some scientific papers\n",
    "    \n",
    "    #Create a dictionary with frequencies and each magnitude and sort aftwerwards for ppg and accelerometer\n",
    "    ppg_dict = dict(zip(freq_ppg, fft_ppg))\n",
    "    sort_ppg_dict = dict(sorted(ppg_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    acc_dict = dict(zip(freq_ppg, fft_ppg))\n",
    "    sort_acc_dict = dict(sorted(acc_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    # Take the frequency without bpm\n",
    "    prev = prev/60\n",
    "    \n",
    "    # Calculates the frequency depending on the limit set between ppg and accelerometer\n",
    "    #if np.abs(list(sort_ppg_dict.keys())[0] - list(sort_acc_dict.keys())[0]) > limit:\n",
    "    if np.abs(list(sort_ppg_dict.keys())[0] - prev) > limit:\n",
    "        dif = list(sort_ppg_dict.keys())[0] - prev\n",
    "        if dif>0:\n",
    "            sel_freq = prev+delta\n",
    "        else:\n",
    "            sel_freq = prev-delta\n",
    "    else:\n",
    "        sel_freq = list(sort_ppg_dict.keys())[0]\n",
    "    \n",
    "    # If they are similar both frequencies, it takes the six biggest and measures the frequency\n",
    "    #else:\n",
    "        \n",
    "        #keys_sort_list = list(sort_ppg_dict.keys())\n",
    "        #print([i*60 for i in [np.abs(prev-keys_sort_list[i]) for i in range(1,8)]])\n",
    "        #argument = np.argmin(np.array([np.abs(prev-keys_sort_list[i]) for i in range(1,6)]))\n",
    "        #sel_freq = list(sort_ppg_dict.keys())[argument+1]\n",
    "\n",
    "    sel_freq = sel_freq*60\n",
    "    \n",
    "    return sel_freq, freq_ppg, fft_ppg\n",
    "\n",
    "def confidence_calc(freqs, fft_mag, bpm_f):\n",
    "    '''Function that calculates the cofidence interval taking those ones which are 15 bpm '''\n",
    "    freqs = freqs*fs\n",
    "    window_f = 15/60\n",
    "    fundamental_freq_window = (freqs > bpm_f - window_f) & (freqs < bpm_f + window_f)\n",
    "    return np.sum(fft_mag[fundamental_freq_window])/ np.sum(fft_mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data and calculate the first one\n",
    "data_fls, ref_fls = LoadTroikaDataset()\n",
    "data_fl, ref_fl = data_fls[0], ref_fls[0]\n",
    "bpm = sp.io.loadmat(ref_fl)['BPM0']\n",
    "err, conf = RunPulseRateAlgorithm(data_fls[0], ref_fls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.70478220689467"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Project Write-up\n",
    "\n",
    "Answer the following prompts to demonstrate understanding of the algorithm you wrote for this specific context.\n",
    "\n",
    "> - **Code Description** - Include details so someone unfamiliar with your project will know how to run your code and use your algorithm. \n",
    "> - **Data Description** - Describe the dataset that was used to train and test the algorithm. Include its short-comings and what data would be required to build a more complete dataset.\n",
    "> - **Algorithhm Description** will include the following:\n",
    ">   - how the algorithm works\n",
    ">   - the specific aspects of the physiology that it takes advantage of\n",
    ">   - a describtion of the algorithm outputs\n",
    ">   - caveats on algorithm outputs \n",
    ">   - common failure modes\n",
    "> - **Algorithm Performance** - Detail how performance was computed (eg. using cross-validation or train-test split) and what metrics were optimized for. Include error metrics that would be relevant to users of your algorithm. Caveat your performance numbers by acknowledging how generalizable they may or may not be on different datasets.\n",
    "\n",
    "**Code Description:** the algorithm takes the frequency and measures the previous one, and looks if it diffears too much from the previous. This is done with a moving windows of length 8s and 2s shift. If the difference from the previous one is too high, it applies a change of a delta 2bpm which is considered by some scientists. Finally it measures the error and the confidence of the prediction.\n",
    "\n",
    "**Data Description:** data used consists on a set with ppg signal and accelerometers at the three axis. It also contains the reference bpm to calculate the error of our algorithm. The ground truth for the reference bpm is ECG. The dataset contains information of 12 patients from 18 to 25 years old doing intensive physical exercise from wrist-type photoplethysmographic signals. The sampling rate of the signal is 125 Hz.\n",
    "\n",
    "The short-commings of the dataset are the low amount of data which can produce to overfit the algorithm and determine an error which not corresponds to reality.\n",
    "\n",
    "**Algorithm Description:** first a bandpass filter is used of 70 to 200 bpm (which is more realistic and offers better results, with less error). Afterwards a moving windows takes 8s of signal and measures the most important frequencies that, if it's different to the previous one by 11 bpm takes a delta value (of 2 bpm) depending if the difference is positive or negative, if not, it takes that one because is considered MAE is not increasing. The evaluation is done with the mean absolute error which had to be lower than 15 bpm.\n",
    "\n",
    "If the frequency of the ppg is similar to the accelerometer's one, this will be confused and the error will increase. Other caveats can be the presence of noise in the PPG which is not visible in the accelerometer, so it could not be seen and will produce algorithm fail.\n",
    "\n",
    "Confidence tells how much energy in the frequency spectrum is concentrated near the pulse rate estimated. So higher value tells the estimate is better.\n",
    "\n",
    "**Algorithm Performance:** the mean absolute error is measured and compared to a reference list measured with an ECG. The MAE takes the absolute value of the difference between the reference value and the estimated one, and finally makes the mean for all the values. It's a way to estimate how is performing our algorithm.\n",
    "\n",
    "In this case, the reference values (ground truth) were calculated with 8s windows of an ECG. By steps of 2s, values were measured and then compared obtaining a value of 12.7 bpm which is lower than 15 bpm (our goal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Next Steps\n",
    "You will now go to **Test Your Algorithm** to apply a unit test to confirm that your algorithm met the success criteria. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
